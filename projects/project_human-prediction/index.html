<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Hugo POUSSEUR</title><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/style.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/color.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/markdown.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css><link rel=icon type=image/png sizes=32x32 href=https://pouceheure.github.io/blog/favicon//favicon-32.png><link rel=icon type=image/png sizes=16x16 href=https://pouceheure.github.io/blog/favicon//favicon-16.png><link rel=icon type=image/png sizes=64x64 href=https://pouceheure.github.io/blog/favicon//favicon-64.png><link rel=apple-touch-icon sizes=180x180 href=https://pouceheure.github.io/blog/favicon//apple-touch-icon.png><link rel="shortcut icon" href=https://pouceheure.github.io/blog/favicon//favicon.ico><style>@media(max-width:767.98px){main{margin-top:112px}}@media(min-width:768px){main{margin-top:56px}}</style></head><body class=bg-light><header><nav class="navbar navbar-expand-md navbar-dark navbar-custom fixed-top bg-primary text-white p-2"><div class="container-fluid px-4 d-flex align-items-center justify-content-between"><a class="navbar-brand fw-bold" href=https://pouceheure.github.io/blog/>Hugo POUSSEUR</a><div class="d-flex align-items-center social-icons ms-md-0 ms-auto"><a href=https://www.linkedin.com/in/hugo-pousseur/ target=_blank class="text-white me-2"><i class="bi bi-linkedin icon-size"></i>
</a><a href=https://github.com/pouceheure/ target=_blank class="text-white me-2"><i class="bi bi-github icon-size"></i>
</a><button type=button class="btn btn-link text-white me-2 p-0" data-bs-toggle=modal data-bs-target=#contactModal>
<i class="bi bi-chat-fill icon-size"></i>
</button>
<a href="https://www.youtube.com/playlist?list=PLGzYzDkg-SZrXPj-0gGwnueRWiMS9GiOM" target=_blank class=text-white><i class="bi bi-youtube icon-size-lg"></i></a></div><div class="collapse navbar-collapse justify-content-end d-none d-md-flex" id=navbarNav><ul class=navbar-nav><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/articles/><span class="d-none d-lg-inline">Scientific </span>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/cv/>About</a></li></ul></div></div></nav><nav class="d-flex d-md-none bg-primary text-white p-2 navbar-dark navbar-custom fixed-top" style=top:56px;z-index:10><div class="container-fluid d-flex justify-content-around"><ul class="navbar-nav flex-row w-100 justify-content-around mb-0"><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/articles/>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/cv/>About</a></li></ul></div></nav></header><main class=container><meta name=description content="Prediction of short-term human driving behavior using previous vehicle states, based on a deep learning model integrating multiple sensors."><meta name=keywords content="ai_ml,robotics_autonomy,ros,sensing_perception"><meta name=author content="Hugo POUSSEUR"><meta property="og:title" content="Human Driving Behavior Prediction"><meta property="og:description" content="Prediction of short-term human driving behavior using previous vehicle states, based on a deep learning model integrating multiple sensors."><meta property="og:type" content="article"><meta property="og:url" content="https://pouceheure.github.io/blog/projects/project_human-prediction/"><meta property="og:image" content="https://pouceheure.github.io/blog/images/human-prediction/projection-prediction-test-1-lane.drawio.png"><link rel=stylesheet href=https://pouceheure.github.io/blog/css/toc.css><div class="container d-flex flex-column flex-md-row align-items-start min-vh-100 gap-4"><aside class="toc w-25 d-none d-lg-block toc-sticky"><div class="toc-container p-3 shadow rounded card d-flex flex-column h-100 card-transparent"><h5 class=toc-title><i class="bi bi-journal-richtext me-1"></i> Contents</h5><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#data-and-model>Data and Model</a><ul><li><a href=#data-categories>Data Categories</a></li><li><a href=#driving-scenarios>Driving Scenarios</a></li><li><a href=#temporal-aspects>Temporal Aspects</a></li><li><a href=#multi-modal-model>Multi-Modal Model</a></li></ul></li><li><a href=#results>Results</a><ul><li><a href=#test-characteristics>Test Characteristics</a></li><li><a href=#example-city-test>Example: City Test</a></li><li><a href=#sensitivity-analysis>Sensitivity Analysis</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></div></aside><article class="markdown-content flex-grow-1 w-100 w-md-75"><h1 class=text-primary>Human Driving Behavior Prediction</h1><div class="d-flex flex-wrap gap-2"><a href=https://pouceheure.github.io/blog/tags/ai_ml/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>AI & ML</strong>
</a><a href=https://pouceheure.github.io/blog/tags/robotics_autonomy/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>Robotics & Autonomy</strong>
</a><a href=https://pouceheure.github.io/blog/tags/ros/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>ROS</strong>
</a><a href=https://pouceheure.github.io/blog/tags/sensing_perception/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>Sensing & Perception</strong>
</a><span class="btn btn-sm btn-info text-white" style=pointer-events:none><i class="bi bi-code-slash"></i>
<strong style=font-size:1.1em>python</strong></span></div><div class="align-items-center mt-2"><a href=https://pouceheure.github.io/blog/articles/article_human-driving-prediction/ class="btn btn-success" style=text-decoration:none><span style=text-decoration:underline><i class="bi bi-book-half"></i></span>
<span style=display:inline-block;width:.25em></span>
<span style=text-decoration:underline>Read Scientific Article</span></a></div><div class=content><h2 id=abstract>Abstract</h2><p>A multimodal deep learning model was developed to predict human driving behavior over a short time horizon. The training dataset was recorded specifically for this project.</p><figure><div class="ratio ratio-16x9" style=max-width:800px;margin:auto><iframe src=https://www.youtube.com/embed/rqP5nYBehL4 allowfullscreen></iframe></div><figcaption>Video 1 - Video demo, human driving behavior prediction.</figcaption></figure><p>More details about this work are provided in
<span class=citation><a href=#ref-PredictionHPousseur>PredictionPousseur 2022</a>
</span>.</p><h2 id=introduction>Introduction</h2><p>Driving intention is represented as a sequence of vehicle states. Let $I$ be:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
I = \{x_0, x_1, ..., x_n\}
\quad \text{Eq (1)} $$</div></div></blockquote><p>Here, $(x_i) = (v_i, w_i)$ denotes the state at time $i$, where $v_i$ is the linear velocity and $w_i$ is the angular velocity.</p><figure id=fig-1><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-human_profile_prediction.drawio.png alt width=500><figcaption>Fig. 1 - Goal of the project.</figcaption></figure><p>The prediction model, $H_\Theta$, aims to produce:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
H_\Theta(X) = \{\hat{y}_{t+1},...,\hat{y}_{t+k}\}
\quad \text{Eq (2)} $$</div></div></blockquote><p>where</p><ul><li>$ \Theta $ are the model parameters, $ X $ is the input vector at time $ t $</li><li>$ \hat{y}_{t+i} $ is the predicted state</li><li>$ (v_{t+i}, w_{t+i}) $ are the predicted velocities</li><li>$ dt $ is the acquisition interval in seconds.</li></ul><h2 id=data-and-model>Data and Model</h2><h3 id=data-categories>Data Categories</h3><p>Input data are grouped into three categories:</p><ul><li><strong>Vehicle state</strong>: velocities, accelerations, and other dynamics.</li><li><strong>Environment state</strong>: map and Lidar data.</li><li><strong>Control state</strong>: steering angle, pedal positions.</li></ul><figure id=fig-2><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-data.drawio.png alt width=500><figcaption>Fig. 2 - Data input.</figcaption></figure><h3 id=driving-scenarios>Driving Scenarios</h3><p>Behavior varies across scenarios such as highways, city streets, and roundabouts. The dataset includes both <strong>structured</strong> (lane-marked roads) and <strong>unstructured</strong> (urban intersections, roundabouts) environments to prevent bias.</p><figure id=fig-3><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-dataset_diversification.drawio.png alt width=500><figcaption>Fig. 3 - Scenario categories.</figcaption></figure><h3 id=temporal-aspects>Temporal Aspects</h3><p>No manual labeling was required; future velocities served as output targets. The sensor acquisition rate is $dt = 100ms$ (10 Hz). A <strong>sliding window</strong> over past states captures temporal dependencies, and <strong>data augmentation</strong> (time warping, resampling) improves generalization.</p><h3 id=multi-modal-model>Multi-Modal Model</h3><p>The model consists of:</p><ol><li><strong>Input model</strong>: compresses each modality into a latent vector.</li><li><strong>Final model</strong>: concatenates latent vectors and applies a recurrent network.</li></ol><figure id=fig-4><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-data_unbalance_old.drawio.png alt width=500><figcaption>Fig. 4 - Handling unbalanced data representation.</figcaption></figure><p>The <strong>input model</strong> uses:</p><ul><li><strong>CNNs</strong> for image-based features (camera, Lidar projections).</li><li><strong>Fully connected layers</strong> for numerical data.</li></ul><p>The <strong>final model</strong> uses <strong>GRUs</strong> for sequence prediction.</p><figure id=fig-5><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-models_architecture.drawio.png alt width=800><figcaption>Fig. 5 - Overall model architecture.</figcaption></figure><h2 id=results>Results</h2><h3 id=test-characteristics>Test Characteristics</h3><div class=table-responsive><table><thead><tr><th>Test Name</th><th>Roundabouts</th><th>Intersections</th><th>Speed Limit</th><th>Distance</th><th>Time Record</th><th>Lanes</th></tr></thead><tbody><tr><td>roundabout</td><td>6</td><td>1</td><td>70 km/h</td><td>4 km</td><td>378 s</td><td>2</td></tr><tr><td>city</td><td>4</td><td>7</td><td>50 km/h</td><td>4 km</td><td>519 s</td><td>1</td></tr><tr><td>speed (1 lane)</td><td>2</td><td>0</td><td>70 km/h</td><td>2 km</td><td>116 s</td><td>1</td></tr><tr><td>speed (2 lanes)</td><td>0</td><td>0</td><td>90 km/h</td><td>2 km</td><td>84 s</td><td>2</td></tr></tbody></table></div><p>The following projections compare predicted and actual trajectories for different scenarios.</p><div class="row justify-content-center"><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-6.1><img src=https://pouceheure.github.io/blog/images/human-prediction/projection-prediction-test-1-lane.drawio.png alt="Test 1 Lane" class=img-fluid><figcaption class=text-muted>Fig. 6.1 - Test 1 Lane</figcaption></figure></div><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-6.2><img src=https://pouceheure.github.io/blog/images/human-prediction/projection-prediction-test-2-lane.drawio.png alt=" Test 2 Lanes" class=img-fluid><figcaption class=text-muted>Fig. 6.2 - Test 2 Lanes</figcaption></figure></div><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-6.3><img src=https://pouceheure.github.io/blog/images/human-prediction/projection-prediction-test-city.drawio.png alt=" Test City" class=img-fluid><figcaption class=text-muted>Fig. 6.3 - Test City</figcaption></figure></div><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-6.4><img src=https://pouceheure.github.io/blog/images/human-prediction/projection-prediction-test-roundabout.drawio.png alt=" Test Roundabout" class=img-fluid><figcaption class=text-muted>Fig. 6.4 - Test Roundabout</figcaption></figure></div></div><figure id=fig-7><img src=https://pouceheure.github.io/blog/images/human-prediction/results_mean.png alt width=500><figcaption>Fig. 7 - Mean errors.</figcaption></figure><p>The error function is:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
loss(y_{predict},y_{true}) = w_{v} \cdot \sum_{i=0}^{n} | y_{predict,v,i} - y_{true,v,i} | + w_{w} \cdot \sum_{i=0}^{n} | y_{predict,w,i} - y_{true,w,i} |
\quad \text{Eq (3)} $$</div></div></blockquote><p>Where:</p><ul><li>$w_v$ is the weight for linear velocity error.</li><li>$w_w$ is the weight for angular velocity error.</li></ul><h3 id=example-city-test>Example: City Test</h3><div class="row justify-content-center"><div class="col-md-6 col-sm-6 col-12 text-center"><figure id=fig-8.1><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-model_city_results_linear.drawio.png alt="Predicted linear velocity" class=img-fluid><figcaption class=text-muted>Fig. 8.1 - Predicted linear velocity</figcaption></figure></div><div class="col-md-6 col-sm-6 col-12 text-center"><figure id=fig-8.2><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-model_city_results_angular.drawio.png alt=" Predicted angular velocity in city scenario" class=img-fluid><figcaption class=text-muted>Fig. 8.2 - Predicted angular velocity in city scenario</figcaption></figure></div></div><h3 id=sensitivity-analysis>Sensitivity Analysis</h3><p>The impact of each input was measured by neutralizing it and observing the change in error. This shows which inputs most influence predictions.</p><p><figure id=fig-9><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-model_sensitivity_motivation.drawio.png alt width=400><figcaption>Fig. 9 - Sensitivity analysis motivation.</figcaption></figure><figure id=fig-10><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-blind.drawio.png alt width=600><figcaption>Fig. 10 - Effect of blind spots.</figcaption></figure><figure id=fig-11><img src=https://pouceheure.github.io/blog/images/human-prediction/scheme-result_v2.drawio.png alt width=800><figcaption>Fig. 11 - Sensitivity analysis results.</figcaption></figure></p><h2 id=references>References</h2><ul><li id=ref-PredictionHPousseur class=citation style=margin-bottom:1em><strong>Prediction of human driving behavior using deep learning: a recurrent learning structure</strong><br><span style=color:#555>Hugo Pousseur, Alessandro Correa Victorino</span><br><em>IEEE ITSC 2022</em><br><a href=https://hal.science/hal-04041186v1/document target=_blank style=font-size:90%;color:#1e88e5>[Access PDF]</a></li></ul></div></article></div><script src=https://pouceheure.github.io/blog/js/highlight-toc.js></script><script src=https://pouceheure.github.io/blog/js/select-toc-part.js></script><script src=https://pouceheure.github.io/blog/js/select-video.js></script></main><div class="modal fade" id=contactModal tabindex=-1 aria-labelledby=contactModalLabel aria-hidden=true><div class="modal-dialog modal-dialog-centered"><div class=modal-content><div class=modal-header><h5 class=modal-title id=contactModalLabel>Contact me</h5><button type=button class=btn-close data-bs-dismiss=modal aria-label=Close></button></div><div class=modal-body><p class=mb-2>Send me email with object starting by [contact-web], email address (click on reveal)</p><code id=email data-noise=~ data-email="=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha">=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha</code><div class=visually-hidden aria-live=polite id=emailLive></div></div><div class=modal-footer><button id=revealEmailBtn class="btn btn-primary">
Reveal Email
</button>
<button type=button class="btn btn-secondary" data-bs-dismiss=modal>
Close</button></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://pouceheure.github.io/blog/js/setup-latex.js></script><script src=https://pouceheure.github.io/blog/js/highlight-navbar.js></script><script src=https://pouceheure.github.io/blog/js/webmail-reveal.js></script></body></html>