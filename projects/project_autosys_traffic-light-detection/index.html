<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Hugo POUSSEUR</title><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/style.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/color.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/markdown.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css><link rel=icon type=image/png sizes=32x32 href=https://pouceheure.github.io/blog/favicon//favicon-32.png><link rel=icon type=image/png sizes=16x16 href=https://pouceheure.github.io/blog/favicon//favicon-16.png><link rel=icon type=image/png sizes=64x64 href=https://pouceheure.github.io/blog/favicon//favicon-64.png><link rel=apple-touch-icon sizes=180x180 href=https://pouceheure.github.io/blog/favicon//apple-touch-icon.png><link rel="shortcut icon" href=https://pouceheure.github.io/blog/favicon//favicon.ico><style>@media(max-width:767.98px){main{margin-top:112px}}@media(min-width:768px){main{margin-top:56px}}</style></head><body class=bg-light><header><nav class="navbar navbar-expand-md navbar-dark navbar-custom fixed-top bg-primary text-white p-2"><div class="container-fluid px-4 d-flex align-items-center justify-content-between"><a class="navbar-brand fw-bold" href=https://pouceheure.github.io/blog/>Hugo POUSSEUR</a><div class="d-flex align-items-center social-icons ms-md-0 ms-auto"><a href=https://www.linkedin.com/in/hugo-pousseur/ target=_blank class="text-white me-2"><i class="bi bi-linkedin icon-size"></i>
</a><a href=https://github.com/pouceheure/ target=_blank class="text-white me-2"><i class="bi bi-github icon-size"></i>
</a><button type=button class="btn btn-link text-white me-2 p-0" data-bs-toggle=modal data-bs-target=#contactModal>
<i class="bi bi-chat-fill icon-size"></i>
</button>
<a href="https://www.youtube.com/playlist?list=PLGzYzDkg-SZrXPj-0gGwnueRWiMS9GiOM" target=_blank class=text-white><i class="bi bi-youtube icon-size-lg"></i></a></div><div class="collapse navbar-collapse justify-content-end d-none d-md-flex" id=navbarNav><ul class=navbar-nav><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/articles/><span class="d-none d-lg-inline">Scientific </span>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/cv/>About</a></li></ul></div></div></nav><nav class="d-flex d-md-none bg-secondary p-2 navbar-dark navbar-custom fixed-top" style=top:56px;z-index:10><div class="container-fluid d-flex justify-content-around"><ul class="navbar-nav flex-row w-100 justify-content-around mb-0"><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/articles/>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/cv/>About</a></li></ul></div></nav></header><main class=container><meta name=description content="Detection of traffic lights, and adaptation of vehicle control depending on the light state."><meta name=keywords content="autonomous_vehicle,control_optimization,core_technologies,robotics_autonomy,ros2,sensing_perception"><meta name=author content="Hugo POUSSEUR"><meta property="og:title" content="Traffic Light Detection & Control"><meta property="og:description" content="Detection of traffic lights, and adaptation of vehicle control depending on the light state."><meta property="og:type" content="article"><meta property="og:url" content="https://pouceheure.github.io/blog/projects/project_autosys_traffic-light-detection/"><meta property="og:image" content="https://pouceheure.github.io/blog/images/traffic_light/thumbnail.png"><link rel=stylesheet href=https://pouceheure.github.io/blog/css/toc.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/markdown-index.css><style>.markdown-content .content h2:first-of-type{margin-top:50px!important}</style><div class="container d-flex flex-column flex-md-row align-items-start min-vh-100 gap-4"><aside class="toc w-30 d-none d-lg-block toc-sticky"><div class="toc-container p-3 shadow rounded card d-flex flex-column h-100 card-transparent"><h5 class=toc-title><i class="bi bi-journal-richtext me-1"></i> Contents</h5><nav id=TableOfContents><ul><li><a href=#motivation>Motivation</a></li><li><a href=#matching>Matching</a></li><li><a href=#detection>Detection</a><ul><li><a href=#dataset>Dataset</a><ul><li><a href=#cameras>Cameras</a></li><li><a href=#labels>Labels</a></li></ul></li><li><a href=#training>Training</a></li><li><a href=#examples>Examples</a></li></ul></li><li><a href=#ros-integration>ROS Integration</a><ul><li><a href=#pipeline>Pipeline</a></li><li><a href=#state-deduction-and-propagation>State Deduction and Propagation</a></li><li><a href=#adaptive-control>Adaptive Control</a></li><li><a href=#rqt>RQT</a></li></ul></li></ul></nav></div></aside><div><article class="markdown-content flex-grow-1 w-100 w-md-75 card-transparent p-2 p-md-3"><h1 class="text-primary mb-4">Traffic Light Detection & Control</h1><div class="d-flex flex-wrap gap-2"><a href=https://pouceheure.github.io/blog/tags/autonomous_vehicle/ class="initial-a btn btn-sm btn-outline-secondary header-badge"><i class="bi bi-tag"></i>
<strong>Autonomous Vehicle</strong>
</a><a href=https://pouceheure.github.io/blog/tags/control_optimization/ class="initial-a btn btn-sm btn-outline-secondary header-badge"><i class="bi bi-tag"></i>
<strong>Control & Optimization</strong>
</a><a href=https://pouceheure.github.io/blog/tags/core_technologies/ class="initial-a btn btn-sm btn-outline-secondary header-badge"><i class="bi bi-tag"></i>
<strong>Core Technologies</strong>
</a><a href=https://pouceheure.github.io/blog/tags/robotics_autonomy/ class="initial-a btn btn-sm btn-outline-secondary header-badge"><i class="bi bi-tag"></i>
<strong>Robotics & Autonomy</strong>
</a><a href=https://pouceheure.github.io/blog/tags/ros2/ class="initial-a btn btn-sm btn-outline-secondary header-badge"><i class="bi bi-tag"></i>
<strong>ROS2</strong>
</a><a href=https://pouceheure.github.io/blog/tags/sensing_perception/ class="initial-a btn btn-sm btn-outline-secondary header-badge"><i class="bi bi-tag"></i>
<strong>Sensing & Perception</strong></a></div><div class=gap-2><span class="btn btn-sm btn-info mt-2 header-badge" style=pointer-events:none><i class="bi bi-code-slash"></i>
<strong>cpp</strong></span></div></article><article class="markdown-content flex-grow-1 w-100 w-md-75 card-transparent p-2 p-md-3 mt-4"><div class=content><h2 id=motivation>Motivation</h2><p>As part of an autonomous driving project, I contributed to the development of a system enabling a vehicle to adapt its behavior to traffic lights. The vehicle adjusts its speed according to the current traffic light state.</p><p>The project is divided into four main components:</p><ul><li><strong>Matching</strong>: Identifying traffic light positions on the map</li><li><strong>Detection</strong>: Determining the current state of the traffic light</li><li><strong>Planning</strong>: Adjusting vehicle speed according to the detection result</li><li><strong>Control</strong>: Applying the computed velocity to the vehicle</li></ul><p>The detection pipeline is implemented in Python, while control is handled in C++ within a ROS2 environment.</p><figure><div class="ratio ratio-16x9" style=max-width:800px;margin:auto><iframe src=https://www.youtube.com/embed/1FJVICEZgao allowfullscreen></iframe></div><figcaption>Video 1 - Demo video: autonomous vehicle adapting control based on traffic light detection.</figcaption></figure><h2 id=matching>Matching</h2><p>Based on the vehicle&rsquo;s planned trajectory, map elements such as traffic lights are projected onto the path.<br>This step does not determine the state of the lights, but flags that a traffic light zone is ahead.</p><h2 id=detection>Detection</h2><p>Within a traffic light zone, the system must identify the current state of the light.</p><p><strong>YOLO</strong> is used for detection. By default, YOLO is not trained to recognize traffic light states; it detects only the presence of a light. A custom YOLO model was therefore trained using a dedicated dataset for this application.</p><h3 id=dataset>Dataset</h3><h4 id=cameras>Cameras</h4><p>Multiple recording sessions were conducted using three different cameras under varying weather conditions (rain and sun) to ensure diversity.<br>This also enabled evaluation of the most suitable camera for detection. Key constraints included:</p><ul><li><strong>Field of view</strong></li><li><strong>Image contrast</strong>, even in direct sunlight</li><li><strong>Ease of mounting and adjustment</strong></li></ul><h4 id=labels>Labels</h4><p>The dataset was annotated with the following labels:</p><ul><li><code>TL_TOP_RED</code>: 0</li><li><code>TL_BOTTOM_RED</code>: 1</li><li><code>TL_TOP_GREEN</code>: 2</li><li><code>TL_BOTTOM_GREEN</code>: 3</li><li><code>TL_TOP_ORANGE</code>: 4</li><li><code>TL_BOTTOM_ORANGE</code>: 5</li></ul><p>This allows the model to distinguish both the position (top or bottom) and the color of the lights.</p><p>The following figure shows dataset distribution. The minimum number of samples per class was targeted. Red lights occur more often due to their longer duration.<br>Camera position also affects distribution: bottom lights are often obscured by trees when far away.</p><figure id=fig-1><img src=https://pouceheure.github.io/blog/images/traffic_light/model/labels_light.png alt width=300><figcaption>Fig. 1 - Label distributions.</figcaption></figure><h3 id=training>Training</h3><p>The YOLO model was trained on this dataset.</p><figure id=fig-2><img src=https://pouceheure.github.io/blog/images/traffic_light/model/train_batch18621.jpg alt width=500><figcaption>Fig. 2 - Batch image example from training.</figcaption></figure><p>Image quality and contrast vary due to different camera sources and YOLO configurations.<br>Data augmentation included transformations, translations, and color adjustments to improve generalization.</p><p>After 500 epochs, the following evaluation results were obtained on the validation set:</p><hr><ul><li><strong>Precision</strong><br><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
\text{Precision} = \frac{TP}{TP + FP}
\quad \text{Eq (1)} $$</div></div></blockquote><br>Measures how often the model’s <em>positive detections</em> (e.g., &ldquo;green top light detected&rdquo;) are correct.<br>A precision close to 1.0 means very few <strong>false positives</strong>, the system rarely claims a light is green/red/orange when it is not.<br><strong>Result:</strong> ≈ 0.99 . Almost every detection made by the system is correct.</li></ul><hr><ul><li><strong>Recall</strong><br><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
\text{Recall} = \frac{TP}{TP + FN}
\quad \text{Eq (2)} $$</div></div></blockquote><br>Measures how many of the <em>actual lights present</em> were detected by the model.<br>A high recall means the model rarely misses a relevant light (<strong>false negatives</strong> are rare).<br><strong>Result:</strong> ≈ 0.97 . The system detects almost all visible traffic lights.</li></ul><hr><ul><li><strong>mAP@0.5</strong><br><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
\text{mAP@0.5} = \text{mean}(AP_{\text{IoU}=0.5})
\quad \text{Eq (3)} $$</div></div></blockquote><br>Mean Average Precision across all classes, calculated at an IoU (Intersection-over-Union) threshold of 0.5.<br>IoU is the overlap ratio between the predicted bounding box and the ground-truth box.<br>A value near 1.0 means the predicted box is well-aligned with the real light location.<br><strong>Result:</strong> ≈ 0.98 . Bounding boxes are accurate for most detections.</li></ul><hr><ul><li><strong>mAP@[0.5:0.95]</strong><br><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
\text{mAP}_{[0.5:0.95]} = \frac{1}{10} \sum_{i=0}^{9} AP_{0.5 + 0.05i}
\quad \text{Eq (4)} $$</div></div></blockquote><br>Average precision computed over multiple IoU thresholds from 0.5 to 0.95 in steps of 0.05.<br>This is a stricter metric than mAP@0.5 because it requires good alignment across a range of IoU tolerances.<br><strong>Result:</strong> ≈ 0.83 . Performance remains high even under stricter bounding box alignment requirements.</li></ul><hr><ul><li><strong>F1-score</strong><br><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\quad \text{Eq (5)} $$</div></div></blockquote><br>The harmonic mean of precision and recall, a balanced single score that considers both false positives and false negatives.<br><strong>Result:</strong> ≈ 0.98 . The detector maintains a strong balance between correctly identifying lights and not missing them.</li></ul><hr><p>These results confirm the detector is both <strong>accurate</strong> (high precision) and <strong>comprehensive</strong> (high recall), with bounding boxes that closely match ground truth (high mAP).<br>This reliability is crucial for control decisions, since a missed red light or a false green could lead to unsafe vehicle behavior.</p><figure id=fig-3><img src=https://pouceheure.github.io/blog/images/traffic_light/model/confusion_matrix_normalized.png alt width=600><figcaption>Fig. 3 - Normalized confusion matrix.</figcaption></figure><div class=table-responsive><table><thead><tr><th>Class</th><th>Accuracy</th><th>Notes</th></tr></thead><tbody><tr><td>TL_TOP_GREEN</td><td>≈ 0.98</td><td>Minor confusion with background and BOTTOM_GREEN</td></tr><tr><td>TL_TOP_RED</td><td>≈ 0.99</td><td>Nearly perfect detection</td></tr><tr><td>TL_BOTTOM_RED</td><td>≈ 0.90</td><td>Some confusion with background</td></tr><tr><td>TL_BOTTOM_GREEN</td><td>≈ 0.97</td><td>Confused with TL_BOTTOM_ORANGE</td></tr><tr><td>TL_TOP_ORANGE</td><td>≈ 0.98</td><td>Minor confusion with BOTTOM_ORANGE and background</td></tr><tr><td>TL_BOTTOM_ORANGE</td><td>≈ 0.96</td><td>Confused with TL_BOTTOM_GREEN</td></tr></tbody></table></div><h3 id=examples>Examples</h3><p>Examples of detection on real-world data are shown below.<br>Current implementation focuses on top lights, as bottom lights are not always visible.</p><div class="row justify-content-center"><div class="col-md-4 col-sm-6 col-12 text-center"><figure id=fig-4.1><img src=https://pouceheure.github.io/blog/images/traffic_light/detection_traffic_light__green_new.png alt="Green top detection." class=img-fluid><figcaption class=text-muted>Fig. 4.1 - Green top detection.</figcaption></figure></div><div class="col-md-4 col-sm-6 col-12 text-center"><figure id=fig-4.2><img src=https://pouceheure.github.io/blog/images/traffic_light/detection_traffic_light__orange_new.png alt=" Orange top detection." class=img-fluid><figcaption class=text-muted>Fig. 4.2 - Orange top detection.</figcaption></figure></div><div class="col-md-4 col-sm-6 col-12 text-center"><figure id=fig-4.3><img src=https://pouceheure.github.io/blog/images/traffic_light/detection_traffic_light__red_new.png alt=" Red top detection." class=img-fluid><figcaption class=text-muted>Fig. 4.3 - Red top detection.</figcaption></figure></div></div><p>The drawn traffic light overlay represents the system&rsquo;s recognized state.</p><h2 id=ros-integration>ROS Integration</h2><h3 id=pipeline>Pipeline</h3><p>The pipeline is divided into four parts:</p><ul><li><strong><code>detection_rate</code></strong>: Adjusts the detection rate of the pipeline by modulating the publishing frequency of the input image, effectively reducing the initial processing rate;</li><li><strong><code>detection_detect</code></strong>: Detects the bounding boxes (<code>bbox</code>) of the <em>TOP_</em> and <em>BOTTOM_</em> elements in the image;</li><li><strong><code>detection_filter</code></strong>: Applies filtering on the detections, for example by name (e.g., excluding <em>BOTTOM</em> elements), by X-position, or by confidence score;</li><li><strong><code>detection_state</code></strong>: Determines the current traffic light state based on the filtered detections.</li></ul><h3 id=state-deduction-and-propagation>State Deduction and Propagation</h3><p>The map is used to identify traffic lights along the planned route.<br>The <code>detection_state</code> node publishes the deduced state of each detected traffic light.</p><p>By default, the state is determined as follows:</p><ul><li>If <strong>TOP_</strong> is detected with sufficient confidence → <strong>STATE = COLOR VALUE</strong> from TOP_{RED, ORANGE, GREEN} class;</li><li>If <strong>TOP_</strong> is not detected with good confidence but <strong>BOTTOM_</strong> is → <strong>STATE = COLOR VALUE</strong> BOTTOM_{RED, ORANGE, GREEN} class;</li><li>If neither TOP_ nor BOTTOM_ provides a reliable classification → <strong>STATE = NOT DETECTED</strong></li></ul><p>The node includes a <strong>timeout</strong> parameter that preserves the last valid detection when no new result is produced, preventing sudden or unwarranted braking.<br>If no detection is available after the timeout, the state becomes <em>not detected</em>, in which case the decision server applies the same precautionary strategy as if the light were red.</p><p>The detection node runs at <strong>10 Hz</strong>, providing a balance between computational cost and system responsiveness. Given the deterministic nature of the model and the camera’s 30 Hz frame rate, increasing the inference rate offers no practical benefit.</p><h3 id=adaptive-control>Adaptive Control</h3><p>Once the traffic light state is determined, the vehicle’s speed profile is adjusted accordingly.</p><p>Each road element (including each traffic light) is associated with a <strong>finite state machine</strong> defining vehicle behavior. A speed profile is assigned based on distance, for example:<br>$ d \in [0, distance_{ahead}],\ speed = profile(d)$.<br><div class=refer-box><i class="bi bi-book"></i> For more details, refer to the <strong>Speed Profile: signal</strong> section of <a href=https://pouceheure.github.io/blog/projects/project_autosys_local-planning/#speed-profile-signal>Planning Project</a>.</div></p><p>The traffic light state machine is defined as:</p><ul><li><code>LOCK</code>: Element is active; vehicle stops before the light</li><li><code>SKIP</code>: Element is ignored; vehicle continues</li><li><code>FREE</code>: Element passed; no longer relevant</li></ul><p><strong>Transitions:</strong></p><ul><li><code>LOCK</code> $\Longleftrightarrow$ <code>SKIP</code></li><li><code>SKIP</code> $\Longrightarrow$ <code>FREE</code></li></ul><p>State updates based on detected light color:</p><ul><li><code>LOCK</code>: red or orange</li><li><code>SKIP</code>: green</li><li><code>FREE</code>: light already passed</li></ul><p>The final control signal is computed by combining all velocity profiles and taking the minimum value at each distance point, ensuring compliance with all constraints.</p><h3 id=rqt>RQT</h3><p>Rqt integration displaying the current traffic light state as perceived by the pipeline and the image annoted.
It&rsquo;s possible to use RQT and then combined rqt_image_view + image state widget, but finnaly the rqt_image_view plugin it&rsquo;s to unstable, and often necessite to reload the topic, to see the image.</p><figure id=fig-5><img src=https://pouceheure.github.io/blog/images/traffic_light/TL_rqt.png alt width=600><figcaption>Fig. 5 - Traffic Light RQT.</figcaption></figure><blockquote><p>The
<a href=#fig-5>Fig. 5</a>
shows a screenshot of the Traffic Light State in RQT. On the left is the image annotated with the position and classification estimates, and on the right is the pipeline’s resulting deduction based on those classification outputs.</p></blockquote></div></article></div></div><script src=https://pouceheure.github.io/blog/js/highlight-toc.js></script><script src=https://pouceheure.github.io/blog/js/counter-toc.js></script><script src=https://pouceheure.github.io/blog/js/select-toc-part.js></script><script src=https://pouceheure.github.io/blog/js/select-video.js></script></main><div class="modal fade" id=contactModal tabindex=-1 aria-labelledby=contactModalLabel aria-hidden=true><div class="modal-dialog modal-dialog-centered"><div class=modal-content><div class=modal-header><h5 class=modal-title id=contactModalLabel>Contact me</h5><button type=button class=btn-close data-bs-dismiss=modal aria-label=Close></button></div><div class=modal-body><p class=mb-2>Send me email with subject starting by [contact-web]. Email address: click on reveal (avoid bot scrapping).</p><code id=email data-noise=~ data-email="=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha">=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha</code><div class=visually-hidden aria-live=polite id=emailLive></div></div><div class=modal-footer><button id=revealEmailBtn class="btn btn-primary">
Reveal Email
</button>
<button type=button class="btn btn-secondary" data-bs-dismiss=modal>
Close</button></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://pouceheure.github.io/blog/js/setup-latex.js></script><script src=https://pouceheure.github.io/blog/js/highlight-navbar.js></script><script>highlightNavbar("https://pouceheure.github.io/blog/")</script><script src=https://pouceheure.github.io/blog/js/webmail-reveal.js></script></body></html>