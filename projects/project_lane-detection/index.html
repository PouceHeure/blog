<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Hugo POUSSEUR</title><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css><link rel=stylesheet href=../../css/style.css><link rel=stylesheet href=../../css/color.css><link rel=stylesheet href=../../css/markdown.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css><link rel=icon type=image/png sizes=32x32 href=../../favicon//favicon-32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon//favicon-16.png><link rel=icon type=image/png sizes=64x64 href=../../favicon//favicon-64.png><link rel=apple-touch-icon sizes=180x180 href=../../favicon//apple-touch-icon.png><link rel="shortcut icon" href=../../favicon//favicon.ico><style>@media(max-width:767.98px){main{margin-top:112px}}@media(min-width:768px){main{margin-top:56px}}</style></head><body class=bg-light><header><nav class="navbar navbar-expand-md navbar-dark navbar-custom fixed-top bg-primary text-white p-2"><div class="container-fluid px-4 d-flex align-items-center justify-content-between"><a class="navbar-brand fw-bold" href=../../>Hugo POUSSEUR</a><div class="d-flex align-items-center social-icons ms-md-0 ms-auto"><a href=https://www.linkedin.com/in/hugo-pousseur/ target=_blank class="text-white me-2"><i class="bi bi-linkedin icon-size"></i>
</a><a href=https://github.com/pouceheure/ target=_blank class="text-white me-2"><i class="bi bi-github icon-size"></i>
</a><a href=# class="text-white me-2" data-bs-toggle=modal data-bs-target=#contactModal><i class="bi bi-chat-fill icon-size"></i>
</a><a href="https://www.youtube.com/playlist?list=PLGzYzDkg-SZrXPj-0gGwnueRWiMS9GiOM" target=_blank class=text-white><i class="bi bi-youtube icon-size-lg"></i></a></div><div class="collapse navbar-collapse justify-content-end d-none d-md-flex" id=navbarNav><ul class=navbar-nav><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=../../>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=../../projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=../../articles/><span class="d-none d-lg-inline">Scientific </span>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=../../cv/>About</a></li></ul></div></div></nav><nav class="d-flex d-md-none bg-primary text-white p-2 navbar-dark navbar-custom fixed-top" style=top:56px;z-index:10><div class="container-fluid d-flex justify-content-around"><ul class="navbar-nav flex-row w-100 justify-content-around mb-0"><li class=nav-item><a class="nav-link text-white fw-bold" href=../../>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=../../projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=../../articles/>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=../../cv/>About</a></li><li class=nav-item><button class="nav-link text-white fw-bold btn btn-link p-0" data-bs-toggle=modal data-bs-target=#contactModal>
<i class="bi bi-chat-fill"></i></button></li></ul></div></nav></header><main class=container><meta name=description content="Lane detection from camera images using a deep-learning autoencoder."><meta name=keywords content="autonomous_vehicle,ai_ml,robotics_autonomy,ros,sensing_perception"><meta name=author content="Hugo POUSSEUR"><meta property="og:title" content="Lane Detection"><meta property="og:description" content="Lane detection from camera images using a deep-learning autoencoder."><meta property="og:type" content="article"><meta property="og:url" content="https://pouceheure.github.io/blog/projects/project_lane-detection/"><meta property="og:image" content="https://pouceheure.github.io/images/lane-detection/detection-result.png"><link rel=stylesheet href=../../css/toc.css><div class="container d-flex flex-column flex-md-row align-items-start min-vh-100 gap-4"><aside class="toc w-25 d-none d-lg-block toc-sticky"><div class="toc-container p-3 shadow rounded card d-flex flex-column h-100 card-transparent"><h5 class=toc-title><i class="bi bi-journal-richtext me-1"></i> Contents</h5><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#deep-learning-architecture>Deep Learning Architecture</a><ul><li><a href=#global-pipeline>Global Pipeline</a></li><li><a href=#autoencoder-design>Autoencoder Design</a></li></ul></li><li><a href=#tracking-module-optional>Tracking Module (Optional)</a></li><li><a href=#post-processing-and-lane-regression>Post-processing and Lane Regression</a></li><li><a href=#visual-results>Visual Results</a></li><li><a href=#integration-with-visual-servoing>Integration with Visual Servoing</a></li><li><a href=#dataset>Dataset</a></li></ul></nav></div></aside><article class="markdown-content flex-grow-1 w-100 w-md-75"><h1 class=text-primary>Lane Detection</h1><div class="d-flex flex-wrap gap-2"><a href=../../tags/autonomous_vehicle/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>Autonomous Vehicle</strong>
</a><a href=../../tags/ai_ml/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>AI & ML</strong>
</a><a href=../../tags/robotics_autonomy/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>Robotics & Autonomy</strong>
</a><a href=../../tags/ros/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>ROS</strong>
</a><a href=../../tags/sensing_perception/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>Sensing & Perception</strong>
</a><span class="btn btn-sm btn-info text-white" style=pointer-events:none><i class="bi bi-code-slash"></i>
<strong style=font-size:1.1em>python</strong></span></div><div class=content><h2 id=abstract>Abstract</h2><p>Lane detection is an essential function for autonomous vehicles. While GPS and HD maps offer accurate localization under optimal conditions, vision-based detection provides an important backup, especially in areas with weak GNSS signals or outdated maps.</p><p>This system implements a deep-learning lane detection pipeline using a convolutional autoencoder, designed to identify and segment multiple lane boundaries in various road conditions using only front-facing camera images.</p><p>The approach integrates image preprocessing, deep-learning inference, optional temporal tracking, and curve fitting to generate stable and clean lane boundaries. It has been tested in real-world driving and in simulators such as Carla and Scaner.</p><figure><div class="ratio ratio-16x9" style=max-width:800px;margin:auto><iframe src=https://www.youtube.com/embed/-KzQhDS5PkY allowfullscreen></iframe></div><figcaption>Video 1 - Video demo of lane detection running online.</figcaption></figure><p>Example detections:</p><p><figure id=fig-1><img src=../../images/lane-detection/example-global.gif alt width=700><figcaption>Fig. 1 - Lane detection output</figcaption></figure><br><figure id=fig-2><img src=../../images/lane-detection/example-global-seg.gif alt width=700><figcaption>Fig. 2 - Lane detection + segmentation (demo 1)</figcaption></figure><br><figure id=fig-3><img src=../../images/lane-detection/example-global-seg-2.gif alt width=700><figcaption>Fig. 3 - Lane detection + segmentation (demo 2)</figcaption></figure></p><h2 id=deep-learning-architecture>Deep Learning Architecture</h2><h3 id=global-pipeline>Global Pipeline</h3><p>The system is organized into several modules:</p><ul><li>Autoencoder: Produces binary lane masks from camera input.</li><li>Tracker (optional): A ConvLSTM-based temporal model for improved frame-to-frame stability.</li><li>Lane Regression: Fits polynomial curves to lane masks.</li><li>Post-processing: Removes outliers and can generate drivable region segmentation.</li></ul><p><figure id=fig-4><img src=../../images/lane-detection/schema-global-pipeline.png alt width=800><figcaption>Fig. 4 - Global lane detection pipeline</figcaption></figure><br><figure id=fig-5><img src=../../images/lane-detection/schema-input-output.png alt width=500><figcaption>Fig. 5 - Input/output shapes for the model</figcaption></figure></p><h3 id=autoencoder-design>Autoencoder Design</h3><p>The convolutional autoencoder performs lane segmentation by encoding spatial information and decoding it into four binary masks: left border, left middle, right middle, and right border.</p><p>Each block contains convolution layers, batch normalization, and ReLU activation. The decoder upsamples using transpose convolutions to restore the original resolution.</p><figure id=fig-6><img src=../../images/lane-detection/models.png alt width=600><figcaption>Fig. 6 - Autoencoder for lane detection: convolutional and upsampling layers producing four segmentation masks.</figcaption></figure><h2 id=tracking-module-optional>Tracking Module (Optional)</h2><p>The ConvLSTM tracker improves predictions by considering the previous N frames, reducing noise and bridging gaps. Training includes noise-augmented data for robustness.</p><p><figure id=fig-7><img src=../../images/lane-detection/schema-tracking-explication.png alt width=800><figcaption>Fig. 7 - Tracking module explanation</figcaption></figure><br><figure id=fig-8><img src=../../images/lane-detection/schema-convlstm-channels.png alt width=800><figcaption>Fig. 8 - ConvLSTM tracking architecture</figcaption></figure><br><figure id=fig-9><img src=../../images/lane-detection/example-tracker-prediction.png alt width=500><figcaption>Fig. 9 - Tracker mask prediction from previous frames</figcaption></figure><br><figure id=fig-10><img src=../../images/lane-detection/example-tracker-raw-prediction.gif alt width=500><figcaption>Fig. 10 - Tracker raw prediction animation</figcaption></figure><br><figure id=fig-11><img src=../../images/lane-detection/example-tracker-improve.gif alt width=500><figcaption>Fig. 11 - Tracker improving lane mask prediction</figcaption></figure></p><h2 id=post-processing-and-lane-regression>Post-processing and Lane Regression</h2><p>After mask prediction, RANSAC polynomial regression fits curves to each lane boundary, rejecting outliers for consistent results.</p><figure id=fig-12><img src=../../images/lane-detection/schema-regression-colors.png alt width=800><figcaption>Fig. 12 - Lane boundary regression pipeline</figcaption></figure><figure id=fig-13><img src=../../images/lane-detection/detection-result.png alt width=700><figcaption>Fig. 13 - Post-processing steps: raw detection, curve fitting, and optional drivable region segmentation.</figcaption></figure><h2 id=visual-results>Visual Results</h2><p>The model performs well with occlusions, worn markings, curves, and lighting variations.</p><div class="row justify-content-center"><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-14.1><img src=../../images/lane-detection/vs_simple.jpg alt="Case: Simple" class=img-fluid><figcaption class=text-muted>Fig. 14.1 - Case: Simple</figcaption></figure></div><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-14.2><img src=../../images/lane-detection/vs_curve.jpg alt=" Case: Curve" class=img-fluid><figcaption class=text-muted>Fig. 14.2 - Case: Curve</figcaption></figure></div><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-14.3><img src=../../images/lane-detection/vs_complexe.jpg alt=" Case: Complex Markings" class=img-fluid><figcaption class=text-muted>Fig. 14.3 - Case: Complex Markings</figcaption></figure></div><div class="col-md-3 col-sm-6 col-12 text-center"><figure id=fig-14.4><img src=../../images/lane-detection/vs_without_mark.jpg alt=" Case: Missing Markings" class=img-fluid><figcaption class=text-muted>Fig. 14.4 - Case: Missing Markings</figcaption></figure></div></div><p>Real-world example:<br><figure id=fig-15><img src=../../images/lane-detection/example-real.gif alt width=500><figcaption>Fig. 15 - Real-world lane detection</figcaption></figure></p><p>Simulator examples:<br>Carla<br><figure id=fig-16><img src=../../images/lane-detection/example-carla.gif alt width=500><figcaption>Fig. 16 - Simulator: Carla</figcaption></figure><br>Scaner<br><figure id=fig-17><img src=../../images/lane-detection/example-scaner.gif alt width=500><figcaption>Fig. 17 - Simulator: Scaner</figcaption></figure></p><h2 id=integration-with-visual-servoing>Integration with Visual Servoing</h2><p>After lane detection, a local path reference is computed.<br>A visual servoing controller adjusts linear velocity $v$ and angular velocity $w$ to minimize deviation from the detected lane centerline.</p><div class=refer-box><i class="bi bi-book"></i> For more details, refer to the project <strong><a href=../../projects/project_visual-control/>Visual Control Project</a></strong></div><h2 id=dataset>Dataset</h2><p>The model is trained on the <a href=https://xingangpan.github.io/projects/CULane.html>CuLane dataset</a>, converted into binary masks using a custom preprocessing script.</p></div></article></div><script src=../../js/highlight-toc.js></script><script src=../../js/select-toc-part.js></script><script src=../../js/select-video.js></script></main><div class="modal fade" id=contactModal tabindex=-1 aria-labelledby=contactModalLabel aria-hidden=true><div class="modal-dialog modal-dialog-centered"><div class=modal-content><div class=modal-header><h5 class=modal-title id=contactModalLabel>Contact me</h5><button type=button class=btn-close data-bs-dismiss=modal aria-label=Close></button></div><div class=modal-body><p class=mb-2>Send me email with object starting by [contact-web], email address (click on reveal)</p><code id=email data-noise=~ data-email="=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha">=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha</code><div class=visually-hidden aria-live=polite id=emailLive></div></div><div class=modal-footer><button id=revealEmailBtn class="btn btn-primary">
Reveal Email
</button>
<button type=button class="btn btn-secondary" data-bs-dismiss=modal>
Close</button></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=../../js/setup-latex.js></script><script src=../../js/highlight-navbar.js></script><script src=../../js/webmail-reveal.js></script></body></html>