<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Hugo POUSSEUR</title><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/style.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/color.css><link rel=stylesheet href=https://pouceheure.github.io/blog/css/markdown.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css><link rel=icon type=image/png sizes=32x32 href=https://pouceheure.github.io/blog/favicon//favicon-32.png><link rel=icon type=image/png sizes=16x16 href=https://pouceheure.github.io/blog/favicon//favicon-16.png><link rel=icon type=image/png sizes=64x64 href=https://pouceheure.github.io/blog/favicon//favicon-64.png><link rel=apple-touch-icon sizes=180x180 href=https://pouceheure.github.io/blog/favicon//apple-touch-icon.png><link rel="shortcut icon" href=https://pouceheure.github.io/blog/favicon//favicon.ico><style>@media(max-width:767.98px){main{margin-top:112px}}@media(min-width:768px){main{margin-top:56px}}</style></head><body class=bg-light><header><nav class="navbar navbar-expand-md navbar-dark navbar-custom fixed-top bg-primary text-white p-2"><div class="container-fluid px-4 d-flex align-items-center justify-content-between"><a class="navbar-brand fw-bold" href=https://pouceheure.github.io/blog/>Hugo POUSSEUR</a><div class="d-flex align-items-center social-icons ms-md-0 ms-auto"><a href=https://www.linkedin.com/in/hugo-pousseur/ target=_blank class="text-white me-2"><i class="bi bi-linkedin icon-size"></i>
</a><a href=https://github.com/pouceheure/ target=_blank class="text-white me-2"><i class="bi bi-github icon-size"></i>
</a><button type=button class="btn btn-link text-white me-2 p-0" data-bs-toggle=modal data-bs-target=#contactModal>
<i class="bi bi-chat-fill icon-size"></i>
</button>
<a href="https://www.youtube.com/playlist?list=PLGzYzDkg-SZrXPj-0gGwnueRWiMS9GiOM" target=_blank class=text-white><i class="bi bi-youtube icon-size-lg"></i></a></div><div class="collapse navbar-collapse justify-content-end d-none d-md-flex" id=navbarNav><ul class=navbar-nav><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/articles/><span class="d-none d-lg-inline">Scientific </span>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold me-3" href=https://pouceheure.github.io/blog/cv/>About</a></li></ul></div></div></nav><nav class="d-flex d-md-none bg-primary text-white p-2 navbar-dark navbar-custom fixed-top" style=top:56px;z-index:10><div class="container-fluid d-flex justify-content-around"><ul class="navbar-nav flex-row w-100 justify-content-around mb-0"><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/>Home</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/projects/>Projects</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/articles/>Articles</a></li><li class=nav-item><a class="nav-link text-white fw-bold" href=https://pouceheure.github.io/blog/cv/>About</a></li></ul></div></nav></header><main class=container><meta name=description content="Road friction estimation based on surface segmentation using a camera and projection into a global grid."><meta name=keywords content="sensing_perception"><meta name=author content="Hugo POUSSEUR"><meta property="og:title" content="Friction Camera Detection"><meta property="og:description" content="Road friction estimation based on surface segmentation using a camera and projection into a global grid."><meta property="og:type" content="article"><meta property="og:url" content="https://pouceheure.github.io/blog/projects/project_friction-detection/"><meta property="og:image" content="https://pouceheure.github.io/blog/images/road-friction/thumbnail.png"><link rel=stylesheet href=https://pouceheure.github.io/blog/css/toc.css><div class="container d-flex flex-column flex-md-row align-items-start min-vh-100 gap-4"><aside class="toc w-25 d-none d-lg-block toc-sticky"><div class="toc-container p-3 shadow rounded card d-flex flex-column h-100 card-transparent"><h5 class=toc-title><i class="bi bi-journal-richtext me-1"></i> Contents</h5><nav id=TableOfContents><ul><li><a href=#mission-context>Mission Context</a></li><li><a href=#image-processing-pipeline>Image Processing Pipeline</a><ul><li><a href=#steps>Steps</a></li></ul></li><li><a href=#projection-and-grid-map-generation>Projection and Grid Map Generation</a><ul><li><a href=#camera-to-world-projection>Camera to World Projection</a></li><li><a href=#accumulation-and-trust-masking>Accumulation and Trust Masking</a></li></ul></li><li><a href=#grid-output-and-road-profile>Grid Output and Road Profile</a></li><li><a href=#runtime-optimization>Runtime Optimization</a></li><li><a href=#experimental-setup>Experimental Setup</a></li><li><a href=#evaluation>Evaluation</a><ul><li><a href=#case-1-double-bluesheet-lane>Case 1: Double Bluesheet Lane</a></li><li><a href=#case-2-asymmetric-surface>Case 2: Asymmetric Surface</a></li></ul></li><li><a href=#slip-ratio-results>Slip Ratio Results</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#references>References</a></li></ul></nav></div></aside><article class="markdown-content flex-grow-1 w-100 w-md-75"><h1 class=text-primary>Friction Camera Detection</h1><div class="d-flex flex-wrap gap-2"><a href=https://pouceheure.github.io/blog/tags/sensing_perception/ class="btn btn-sm btn-secondary"><i class="bi bi-tag"></i>
<strong style=font-size:1.1em>Sensing & Perception</strong>
</a><span class="btn btn-sm btn-info text-white" style=pointer-events:none><i class="bi bi-code-slash"></i>
<strong style=font-size:1.1em>python</strong></span></div><div class="align-items-center mt-2"><a href=https://pouceheure.github.io/blog/articles/article_camera-based-control/ class="btn btn-success" style=text-decoration:none><span style=text-decoration:underline><i class="bi bi-book-half"></i></span>
<span style=display:inline-block;width:.25em></span>
<span style=text-decoration:underline>Read Scientific Article</span></a></div><div class=content><h2 id=mission-context>Mission Context</h2><p>As part of a European research project, I contributed to a two-month research mission conducted at the University of Tokyo, focusing on road surface friction estimation using only a forward-facing camera.</p><p>This work led to the publication of a paper,
<span class=citation><a href=#ref-ProposalUTakumi>ProposalTakumi 2023</a>
</span>, at IEEE AIM 2023, in collaboration with the University of Tokyo and UTC. The system uses image segmentation, confidence modeling, geometric projection, and accumulation into a global surface grid map.</p><figure id=road-friction-demo><div class="ratio ratio-16x9" style=max-width:800px;margin:auto><iframe src=https://www.youtube.com/embed/mbmAByTlTSU allowfullscreen></iframe></div><figcaption>Video 1 - Video demo: road friction estimation.</figcaption></figure><p>Demo:
<a href=#road-friction-demo>Video 1: Video demo: road friction estimation.</a>
.</p><p>The experiment was conducted with the Fujimoto Lab (University of Tokyo) as part of the OWheel collaboration. The laboratory specializes in autonomous vehicles and control systems, particularly for electric vehicles and in-wheel motor platforms.</p><figure id=fig-1><img src=https://pouceheure.github.io/blog/images/road-friction/fujimoto_laboratory.jpg alt width=500><figcaption>Fig. 1 - Laboratories of the University of Tokyo, Kashiwa campus.</figcaption></figure><p>The mission aimed to detect road surface types in real time from a front-facing camera and provide this information to a traction controller.</p><h2 id=image-processing-pipeline>Image Processing Pipeline</h2><h3 id=steps>Steps</h3><ol><li>ROI selection</li><li>Color distance computation</li><li>Binary thresholding</li><li>Image downsampling</li><li>Confidence mask application</li></ol><figure id=fig-2><img src=https://pouceheure.github.io/blog/images/road-friction/ip_process.png alt width=700><figcaption>Fig. 2 - Five-step processing pipeline from RGB image to pixel-level friction prediction.</figcaption></figure><p>The image classifier generates:</p><ul><li><strong>ROAD</strong> (normal traction)</li><li><strong>SLIPPERY</strong> (blue polymer)</li><li><strong>UNKNOWN</strong></li></ul><figure id=fig-3><img src=https://pouceheure.github.io/blog/images/road-friction/image_processing_results.png alt width=700><figcaption>Fig. 3 - Left: original image. Middle: binary mask. Right: confidence-weighted prediction.</figcaption></figure><h2 id=projection-and-grid-map-generation>Projection and Grid Map Generation</h2><h3 id=camera-to-world-projection>Camera to World Projection</h3><p>Each pixel $(u, v)$ is projected into 3D space using:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
x_c = \frac{(u - c_x)}{f_x} \cdot z(v)
\quad \text{Eq (1)} $$</div></div></blockquote><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
y_c = \frac{(v - c_y)}{f_y} \cdot z(v)
\quad \text{Eq (2)} $$</div></div></blockquote><p>where $z(v)$ is the estimated distance from camera to ground, obtained via linear regression.</p><p>Pose correction is performed using <strong>GPS + IMU + Kalman filter</strong> to convert pixel coordinates into world coordinates for insertion into a 2D grid.</p><figure id=fig-4><img src=https://pouceheure.github.io/blog/images/road-friction/image_projection.png alt width=700><figcaption>Fig. 4 - Pipeline: projecting detection to grid map using calibrated camera + GPS pose.</figcaption></figure><h3 id=accumulation-and-trust-masking>Accumulation and Trust Masking</h3><p>Each grid cell is updated over multiple frames to improve stability. Confidence is reduced for distant pixels due to higher projection error and reduced color reliability.</p><figure id=fig-5><img src=https://pouceheure.github.io/blog/images/road-friction/data_binary_trust_mask.png alt width=700><figcaption>Fig. 5 - Trust mask improves reliability in central image zones.</figcaption></figure><h2 id=grid-output-and-road-profile>Grid Output and Road Profile</h2><p>The global grid stores accumulated surface classifications over time, with two buffers:</p><ul><li>$B_{ij}$: slippery surface class (blue-sheet)</li><li>$R_{ij}$: normal road class</li></ul><p>Update rule:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
\begin{cases}
B_{ij} \leftarrow B_{ij} + \hat{p}_{uv}, & \text{if } \hat{p}_{uv} > 0 \\
R_{ij} \leftarrow R_{ij} + \hat{p}_{uv}, & \text{if } \hat{p}_{uv} < 0
\end{cases}
\quad \text{Eq (3)} $$</div></div></blockquote><p>Final grid value:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
G_{ij} =
\begin{cases}
\frac{B_{ij} + R_{ij}}{|B_{ij}| + |R_{ij}|}, & \text{if } |B_{ij}| + |R_{ij}| \neq 0 \\
0, & \text{else}
\end{cases}
\quad \text{Eq (4)} $$</div></div></blockquote><p>This grid is used to build <strong>friction profiles</strong> for left and right wheels.</p><figure id=fig-6><img src=https://pouceheure.github.io/blog/images/road-friction/output_road_friction_detection.png alt width=700><figcaption>Fig. 6 - Example of final friction profile used by controller.</figcaption></figure><h2 id=runtime-optimization>Runtime Optimization</h2><p>Image resolution reduction was crucial. Projection runtime decreased by over $10\times$ when images were resized before processing.</p><figure id=fig-7><img src=https://pouceheure.github.io/blog/images/road-friction/data_plot_with_reduction.png alt width=500><figcaption>Fig. 7 - With downsampling: efficient per-frame processing time.</figcaption></figure><h2 id=experimental-setup>Experimental Setup</h2><ul><li>EV testbed with onboard RGB camera and GPS</li><li>Blue polymer simulating slippery surfaces</li><li>Kalman filtering to improve GPS positioning</li><li>Real-time fusion of camera and pose data</li></ul><figure id=fig-8><img src=https://pouceheure.github.io/blog/images/road-friction/tool_recorder.png alt width=600><figcaption>Fig. 8 - Custom tool for GPS + Camera synchronized dataset creation.</figcaption></figure><figure id=fig-9><img src=https://pouceheure.github.io/blog/images/road-friction/data_gps_issue_efk.png alt width=700><figcaption>Fig. 9 - Left: raw GPS. Right: with Kalman filtering.</figcaption></figure><h2 id=evaluation>Evaluation</h2><h3 id=case-1-double-bluesheet-lane>Case 1: Double Bluesheet Lane</h3><figure id=fig-10><img src=https://pouceheure.github.io/blog/images/road-friction/profiles/double/image_scenario_selected.png alt width=400><figcaption>Fig. 10 - Vehicle on symmetrical slippery zones.</figcaption></figure><figure id=fig-11><img src=https://pouceheure.github.io/blog/images/road-friction/profiles/double/plot_road_profiles.png alt width=600><figcaption>Fig. 11 - Profile generated from friction grid.</figcaption></figure><figure id=fig-12><img src=https://pouceheure.github.io/blog/images/road-friction/profiles/double/plot_road_profiles_errors.png alt width=600><figcaption>Fig. 12 - Distance error between predicted and true profile.</figcaption></figure><h3 id=case-2-asymmetric-surface>Case 2: Asymmetric Surface</h3><figure id=fig-13><img src=https://pouceheure.github.io/blog/images/road-friction/profiles/mixed/image_scenario_selected.png alt width=400><figcaption>Fig. 13 - Vehicle with offset slippery zone.</figcaption></figure><figure id=fig-14><img src=https://pouceheure.github.io/blog/images/road-friction/profiles/mixed/plot_road_profiles.png alt width=600><figcaption>Fig. 14 - Estimated friction profile (asymmetric).</figcaption></figure><figure id=fig-15><img src=https://pouceheure.github.io/blog/images/road-friction/profiles/mixed/plot_road_profiles_errors.png alt width=600><figcaption>Fig. 15 - Prediction error across path length.</figcaption></figure><h2 id=slip-ratio-results>Slip Ratio Results</h2><blockquote><p>More information about control part, refer to the article
<span class=citation><a href=#ref-ProposalUTakumi>ProposalTakumi 2023</a>
</span>.</p></blockquote><p>Slip ratio is defined as:</p><blockquote><div class=equation-scroll-wrapper><div class=equation-block>$$
s = \frac{Rw - u}{Rw}
\quad \text{Eq (5)} $$</div></div></blockquote><p>Where:</p><ul><li>$Rw$: wheel speed</li><li>$u$: vehicle forward velocity</li></ul><p>Visual-based friction prediction reduced slip ratio <strong>by 50%</strong> compared to wheel-only estimation.</p><figure id=fig-16><img src=https://pouceheure.github.io/blog/images/road-friction/slip_results.png alt width=700><figcaption>Fig. 16 - Slip ratio: visual-based control (red) vs. wheel-sensor-only (blue).</figcaption></figure><h2 id=conclusion>Conclusion</h2><ul><li>Camera-based approach enables accurate real-time road surface detection</li><li>Friction grid provides stable and reliable predictions</li><li>System demonstrated real-time compatibility</li><li>Traction controller performance improved with reduced slip</li></ul><p>This confirms vision as a feasible solution for low-cost and anticipatory traction control in autonomous and semi-autonomous vehicles.</p><h2 id=references>References</h2><ul><li id=ref-ProposalUTakumi class=citation style=margin-bottom:1em><strong>Proposal of On-board Camera-Based Driving Force Control Method for Autonomous Electric Vehicles</strong><br><span style=color:#555>Takumi Ueno, Hugo Pousseur, Binh Minh Nguyen, Alessandro Victorino, Hiroshi Fujimoto</span><br><em>IEEE/ASME AIM 2023</em><br><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196211" target=_blank style=font-size:90%;color:#1e88e5>[Access PDF]</a></li></ul></div></article></div><script src=https://pouceheure.github.io/blog/js/highlight-toc.js></script><script src=https://pouceheure.github.io/blog/js/select-toc-part.js></script><script src=https://pouceheure.github.io/blog/js/select-video.js></script></main><div class="modal fade" id=contactModal tabindex=-1 aria-labelledby=contactModalLabel aria-hidden=true><div class="modal-dialog modal-dialog-centered"><div class=modal-content><div class=modal-header><h5 class=modal-title id=contactModalLabel>Contact me</h5><button type=button class=btn-close data-bs-dismiss=modal aria-label=Close></button></div><div class=modal-body><p class=mb-2>Send me email with object starting by [contact-web], email address (click on reveal)</p><code id=email data-noise=~ data-email="=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha">=02~bj5~Cbp~FWb~nBk~c1V~2cz~V3b~w5y~bnV~Ha</code><div class=visually-hidden aria-live=polite id=emailLive></div></div><div class=modal-footer><button id=revealEmailBtn class="btn btn-primary">
Reveal Email
</button>
<button type=button class="btn btn-secondary" data-bs-dismiss=modal>
Close</button></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://pouceheure.github.io/blog/js/setup-latex.js></script><script src=https://pouceheure.github.io/blog/js/highlight-navbar.js></script><script src=https://pouceheure.github.io/blog/js/webmail-reveal.js></script></body></html>